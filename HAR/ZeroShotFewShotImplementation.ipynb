{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4990aa01-2e28-4f6b-be28-b65e1b3297dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secret\n",
    "key = secret.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ea4ba6-0336-43bd-9f11-e26f98177fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MakeDataset import X_train,X_test,y_train,y_test\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import os\n",
    "\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING'            ,\n",
    "    2: 'WALKING_UPSTAIRS'   ,\n",
    "    3: 'WALKING_DOWNSTAIRS' ,\n",
    "    4: 'SITTING'            ,\n",
    "    5: 'STANDING'           ,\n",
    "    6: 'LAYING'             ,\n",
    "}\n",
    "\n",
    "columns = [\"accx\",\"accy\",\"accz\"]\n",
    "subject_test = [10,12,13,18,2,20,24,4,9]\n",
    "subject_train = [1,11,14,15,16,17,19,21,22,23,25,26,27,28,29,3,30,5,6,7,8]\n",
    "\n",
    "Groq_Token = key\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model = 'llama3.1-70b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f4838a-9ea9-4498-8d96-b36a000a1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "accx_train = X_train[:,:,0]\n",
    "accy_train = X_train[:,:,1]\n",
    "accz_train = X_train[:,:,2]\n",
    "\n",
    "accx_train_1 = accx_train[np.where(y_train==1)]\n",
    "accy_train_1 = accy_train[np.where(y_train==1)]\n",
    "accz_train_1 = accz_train[np.where(y_train==1)]\n",
    "\n",
    "accx_train_2 = accx_train[np.where(y_train==2)]\n",
    "accy_train_2 = accy_train[np.where(y_train==2)]\n",
    "accz_train_2 = accz_train[np.where(y_train==2)]\n",
    "\n",
    "accx_train_3 = accx_train[np.where(y_train==3)]\n",
    "accy_train_3 = accy_train[np.where(y_train==3)]\n",
    "accz_train_3 = accz_train[np.where(y_train==3)]\n",
    "\n",
    "accx_train_4 = accx_train[np.where(y_train==4)]\n",
    "accy_train_4 = accy_train[np.where(y_train==4)]\n",
    "accz_train_4 = accz_train[np.where(y_train==4)]\n",
    "\n",
    "accx_train_5 = accx_train[np.where(y_train==5)]\n",
    "accy_train_5 = accy_train[np.where(y_train==5)]\n",
    "accz_train_5 = accz_train[np.where(y_train==5)]\n",
    "\n",
    "accx_train_6 = accx_train[np.where(y_train==6)]\n",
    "accy_train_6 = accy_train[np.where(y_train==6)]\n",
    "accz_train_6 = accz_train[np.where(y_train==6)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accx_test = X_test[:,:,0]\n",
    "accy_test = X_test[:,:,1]\n",
    "accz_test = X_test[:,:,2]\n",
    "\n",
    "accx_test_1 = accx_test[np.where(y_test==1)]\n",
    "accy_test_1 = accy_test[np.where(y_test==1)]\n",
    "accz_test_1 = accz_test[np.where(y_test==1)]\n",
    "\n",
    "accx_test_2 = accx_test[np.where(y_test==2)]\n",
    "accy_test_2 = accy_test[np.where(y_test==2)]\n",
    "accz_test_2 = accz_test[np.where(y_test==2)]\n",
    "\n",
    "accx_test_3 = accx_test[np.where(y_test==3)]\n",
    "accy_test_3 = accy_test[np.where(y_test==3)]\n",
    "accz_test_3 = accz_test[np.where(y_test==3)]\n",
    "\n",
    "accx_test_4 = accx_test[np.where(y_test==4)]\n",
    "accy_test_4 = accy_test[np.where(y_test==4)]\n",
    "accz_test_4 = accz_test[np.where(y_test==4)]\n",
    "\n",
    "accx_test_5 = accx_test[np.where(y_test==5)]\n",
    "accy_test_5 = accy_test[np.where(y_test==5)]\n",
    "accz_test_5 = accz_test[np.where(y_test==5)]\n",
    "\n",
    "accx_test_6 = accx_test[np.where(y_test==6)]\n",
    "accy_test_6 = accy_test[np.where(y_test==6)]\n",
    "accz_test_6 = accz_test[np.where(y_test==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea07eaa-ffaa-4827-b367-610e29c1c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accx_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66ecd1-5ac0-4585-b0cd-466d92ddcffa",
   "metadata": {},
   "source": [
    "# Q1 \n",
    "## Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98992901-f7cb-4234-bc23-6afe2336fb47",
   "metadata": {},
   "source": [
    "Comparing zero shot with few shot.\n",
    "Zero shot learning aims to recognize the instances from classes that it has never seen before. Generalizing from seen classes to unseen ones purely based on semantic information, which can be quite difficult if the semantic relationships are weak or ambiguous.\n",
    "\n",
    "Whereas in few shot learning the model has access to a small number of samples from the target class, making it easier to fine-tune or adjust its internal representations for better accuracy.\n",
    "\n",
    "Out of the following two cells the first one is implemtation of zero shot and the other is of few shot. We can observe that in the first response when the data is directly given for classification the model generalizes the idea of movement in x,y and z directions and using it as premises it classifies the activities. It tries to use the general idea e.g while walking the acceleration in x should be considerably high with respect to the other axis. Similar inferences are made for all the activities.\n",
    "\n",
    "While in the few shot learning, the model first analyses the data provided for each of the activities and performs some statistical operations and builds the conclusion. Here, the accuracy rate is significantly high as compared to former case. This is beacuse the model now has the acces to relevant data to study the examples and provide better inferences.\n",
    "\n",
    "So, to put answer in simple words, the zero shot approach doesn't have access to the data and it generalizes its own understandings to the given dataset.On contrary in the few shot approach the model has access to some samples of the data to learn from and then accordingly classify the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1d8519-34fb-41e7-ad64-5cfe41f63811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given data, the activity being represented is walking.\n"
     ]
    }
   ],
   "source": [
    "# zero shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with experimental data containing acceleration in x, y, and z directions. \n",
    "This data is collected from humans performing the following activities:\n",
    "1. Walking\n",
    "2. Walking Upstairs\n",
    "3. Walking Downstairs\n",
    "4. Sitting\n",
    "5. Standing\n",
    "6. Laying\n",
    "\n",
    "Your task is to analyze the raw data and determine which activity is being represented based on the above-mentioned activities. \n",
    "The acceleration data contains multiple readings of the same activity in a 2D array, with the shape (number of samples, number of readings per axis).\n",
    "\n",
    "Acceleration in x direction: {accx_test_1.tolist()}\n",
    "Acceleration in y direction: {accy_test_1.tolist()}\n",
    "Acceleration in z direction: {accz_test_1.tolist()}\n",
    "Mean in x direction: {accx_test_1.mean()}\n",
    "Mean in y direction: {accy_test_1.mean()}\n",
    "Mean in z direction: {accz_test_1.mean()}\n",
    "Standard deviation in x direction: {accx_test_1.std()}\n",
    "Standard deviation in y direction: {accy_test_1.std()}\n",
    "Standard deviation in z direction: {accz_test_1.std()}\n",
    "Max value in x direction: {accx_test_1.max()}\n",
    "Max value in y direction: {accy_test_1.max()}\n",
    "Max value in z direction: {accz_test_1.max()}\n",
    "Min value in x direction: {accx_test_1.min()}\n",
    "Min value in y direction: {accy_test_1.min()}\n",
    "Min value in z direction: {accx_test_1.min()}\n",
    "Median in x direction: {np.median(accx_test_1)}\n",
    "Median in y direction: {np.median(accy_test_1)}\n",
    "Median in z direction: {np.median(accz_test_1)}\n",
    "\n",
    "Give the answer from the above mentioned activities along with the number specified\n",
    "\"\"\"\n",
    "\n",
    "\n",
    " \n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cee8b14-79eb-4cc9-9028-cf3766e21cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.WALKING_UPSTAIRS\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "Acceleration in x direction: {accx_train_3.ravel()}\n",
    "Acceleration in y direction: {accy_train_3.ravel()}\n",
    "Acceleration in z direction: {accz_train_3.ravel()}\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "Acceleration in x direction: {accx_train_5.ravel()}\n",
    "Acceleration in y direction: {accy_train_5.ravel()}\n",
    "Acceleration in z direction: {accz_train_5.ravel()}\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Your response should not contain any other explanation just answer in format e.g. 2.WALKING_UPSTAIRS\n",
    "\n",
    "You can perform PCA analysis,statistical analysis like mean,mode,median,standard deviation and other sush relevant analysis to find the typeof activity\n",
    "\n",
    "Acceleration in x direction: {accx_test_2.ravel()}\n",
    "Acceleration in y direction: {accy_test_2.ravel()}\n",
    "Acceleration in z direction: {accz_test_2.ravel()}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52e5d9-a615-47b5-ba89-92e51579c066",
   "metadata": {},
   "source": [
    "# Q2\n",
    "## Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb247c",
   "metadata": {},
   "source": [
    "Inferences :\n",
    "The LLM is messing up while classifying the the dynamic activities of walking,walking_upstairs and walking downstairs.\n",
    "Whereas while classifying the static activities it has pretty good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91638825-01ef-406b-a37e-f497ff86f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  3\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  3\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "6.LAYING\n",
      "Predicted:  6\n",
      "Actual:  6\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "4.SITTING\n",
      "Predicted:  4\n",
      "Actual:  6\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "6.LAYING\n",
      "Predicted:  6\n",
      "Actual:  6\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "6.LAYING\n",
      "Predicted:  6\n",
      "Actual:  6\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  5\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  5\n",
      "\n",
      "5.STANDING\n",
      "Predicted:  5\n",
      "Actual:  4\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  3\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "4.SITTING\n",
      "Predicted:  4\n",
      "Actual:  4\n",
      "\n",
      "6.LAYING\n",
      "Predicted:  6\n",
      "Actual:  6\n",
      "\n",
      "4.SITTING\n",
      "Predicted:  4\n",
      "Actual:  4\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  1\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "6.LAYING\n",
      "Predicted:  6\n",
      "Actual:  6\n",
      "\n",
      "2.WALKING_UPSTAIRS\n",
      "Predicted:  2\n",
      "Actual:  2\n",
      "\n",
      "4.SITTING\n",
      "Predicted:  4\n",
      "Actual:  4\n",
      "\n",
      "4.SITTING\n",
      "Predicted:  4\n",
      "Actual:  4\n",
      "\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     55\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGroq(model\u001b[38;5;241m=\u001b[39mgroq_models[model_name], api_key\u001b[38;5;241m=\u001b[39mGroq_Token, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     59\u001b[0m words \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:291\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    288\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    290\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 291\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    301\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:791\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    785\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:648\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    647\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 648\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    649\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    650\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    652\u001b[0m ]\n\u001b[1;32m    653\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:638\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 638\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m         )\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 860\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/langchain_groq/chat_models.py:472\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    468\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    471\u001b[0m }\n\u001b[0;32m--> 472\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/groq/resources/chat/completions.py:289\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/groq/_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1224\u001b[0m     )\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/groq/_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    919\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/groq/_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1017\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1021\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1022\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1026\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "idxs = []\n",
    "\n",
    "for i in range(accx_test.shape[0]):\n",
    "    feed_x = accx_test[i]\n",
    "    feed_y = accy_test[i]\n",
    "    feed_z = accz_test[i]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "Acceleration in x direction: {accx_train_3.ravel()}\n",
    "Acceleration in y direction: {accy_train_3.ravel()}\n",
    "Acceleration in z direction: {accz_train_3.ravel()}\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "Acceleration in x direction: {accx_train_5.ravel()}\n",
    "Acceleration in y direction: {accy_train_5.ravel()}\n",
    "Acceleration in z direction: {accz_train_5.ravel()}\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Your response should not contain any other explanation just answer in format e.g. 2.WALKING_UPSTAIRS\n",
    "\n",
    "You can perform PCA analysis,statistical analysis like mean,mode,median,standard deviation and other sush relevant analysis to find the typeof activity\n",
    "\n",
    "Acceleration in x direction: {feed_x.ravel()}\n",
    "Acceleration in y direction: {feed_y.ravel()}\n",
    "Acceleration in z direction: {feed_z.ravel()}\n",
    "    \"\"\" \n",
    "    \n",
    "    model_name = model\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    print(answer.content)\n",
    "    words = answer.content.split(\".\")\n",
    "    required = words[-1].split(\":\")[-1]\n",
    "    predictions.append(words[0])\n",
    "    idxs.append(i)\n",
    "    print(\"Predicted: \",predictions[-1])\n",
    "    print(\"Actual: \",y_test[i])\n",
    "    print()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c47f42a-570c-4e0a-a12e-9e08a3b4984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 5, 5, 2, 2, 5, 2, 2, 6, 5, 4, 5, 6, 2, 6, 2, 2, 5, 5, 2, 2, 2, 2, 4, 6, 4, 2, 2, 6, 2, 4, 4]\n",
      "[3 1 2 5 5 1 1 5 3 2 6 5 6 5 6 1 6 5 2 5 4 3 2 2 1 4 6 4 1 2 6 2 4 4]\n",
      "\n",
      "\n",
      "\n",
      "Total Accuracy of few shot: 64.71%\n",
      "Accuracy in Dynamic activities is 43.75%\n",
      "Accuracy in Static activities is 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Checking the predictions data\n",
    "predictions = [int(i) for i in predictions]\n",
    "print(predictions)\n",
    "print(y_test[idxs])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "y_test_filtered = y_test[idxs]\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(p == y for p, y in zip(predictions, y_test_filtered))\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Total Accuracy of few shot: {accuracy:.2%}\")\n",
    "\n",
    "dynamic_test = []\n",
    "dynamic_predict = []\n",
    "\n",
    "static_test = []\n",
    "static_predict = []\n",
    "\n",
    "for i in range(len(y_test_filtered)):\n",
    "    if y_test_filtered[i] in [1,2,3]:\n",
    "        dynamic_predict.append(predictions[i])\n",
    "        dynamic_test.append(y_test_filtered[i])\n",
    "    \n",
    "    if y_test_filtered[i] in [4,5,6]:\n",
    "        static_predict.append(predictions[i])\n",
    "        static_test.append(y_test_filtered[i])\n",
    "\n",
    "\n",
    "dynamic_accuracy = sum(p == y for p,y in zip(dynamic_predict,dynamic_test))/len(dynamic_predict)\n",
    "print(f\"Accuracy in Dynamic activities is {dynamic_accuracy:.2%}\")\n",
    "\n",
    "static_accuracy = sum(p == y for p,y in zip(static_predict,static_test))/len(static_predict)\n",
    "print(f\"Accuracy in Static activities is {static_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835d923-d308-4208-b03f-b7df4b50ead6",
   "metadata": {},
   "source": [
    "# Q3\n",
    "## What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f2096-171c-4325-b72d-928ff780981b",
   "metadata": {},
   "source": [
    "### Limitations of zero shot and few shot in context of classifying human activities based on featurezied data\n",
    "\n",
    "1) Semantic Description : ZSL and FSL depends on the quality of prompt we are using to descibe the problem statement.If these prompts are not structured properly then the models ability to recognize the activities may suffer. Somtimes it is difficult to structure the data into semantic manner.\n",
    "2) Contraints Related to data: At a time we can input only certain quantity of data that to in semantic way. So the model has very less data to work with leading to very high inaccuracy. Also we have to embed the data into semantic prompt which limits our capability to featurize the data and provide all the featurized data.If the data is too noisy then the LLM will struggle to learn from the few samples we provided.\n",
    "3) Generalization: These LLMs tries to generalize their understanding for the given data. This error can be reduced if we use FSL where we provide some sample data to model for its training. But in ZSL the LLM tries to generalize completely because it has not seen the data we fed before. So even in FSL there is generalization to some extent. \n",
    "4) Limited Adaptibility: Both ZSL and FSL face challenges when dealing with activities that are inherently complex or involve multiple stages or types of movements. These models often struggle to accurately classify such activities. In the case of FSL, when an activity not represented in the training data is encountered, the model tends to forcefully classify it as one of the known activities rather than recognizing it as an entirely new or different activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48b14a-46d7-4d0b-83c3-6e2f5cc27d7e",
   "metadata": {},
   "source": [
    "# Q4\n",
    "## What does the model classify when given input from an entirely new activity that it hasn't seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8465358-5855-4d33-b1a8-c36a52a7e392",
   "metadata": {},
   "source": [
    "In this scenario, the model has been trained on data from only four specific activities, excluding the 'Standing' and 'Walking' activities, although these two activities are included in the list of possible predictions. When the model is given data related to 'Standing' or 'Walking,' it tends to force the data into one of the four activities it has seen during training, often failing to recognize or accurately classify the 'Standing' or 'Walking' activities. As a result, the model consistently misclassifies these activities because it lacks the necessary training data to correctly identify them, despite their presence in the prediction list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04aba2-b217-40fd-9d02-eb711b5dcb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided data, I will attempt to identify the activity represented by the raw data.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "1. The acceleration values in the x, y, and z directions are relatively stable, with some fluctuations.\n",
      "2. The x-axis acceleration values are mostly positive, indicating movement in the forward direction.\n",
      "3. The y-axis acceleration values are mostly negative, indicating movement in the downward direction.\n",
      "4. The z-axis acceleration values are relatively small, indicating minimal movement in the vertical direction.\n",
      "\n",
      "**Comparison with the provided activities:**\n",
      "\n",
      "1. **WALKING**: The x-axis acceleration values are similar to those in the provided walking data, with a range of approximately 0.8 to 1.2. The y-axis acceleration values are also similar, with a range of approximately -0.2 to -0.1.\n",
      "2. **WALKING_UPSTAIRS**: The x-axis acceleration values are higher than those in the provided walking data, with a range of approximately 1.2 to 1.5. The y-axis acceleration values are also higher, with a range of approximately -0.1 to 0.1.\n",
      "3. **WALKING_DOWNSTAIRS**: Not enough data is provided to make a comparison.\n",
      "4. **SITTING**: The x-axis acceleration values are lower than those in the provided walking data, with a range of approximately 0.7 to 0.9. The y-axis acceleration values are also lower, with a range of approximately 0.4 to 0.5.\n",
      "5. **STANDING**: Not enough data is provided to make a comparison.\n",
      "6. **LAYING**: The x-axis acceleration values are lower than those in the provided walking data, with a range of approximately 0.2 to 0.4. The y-axis acceleration values are also lower, with a range of approximately 0.5 to 0.6.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the observations and comparisons, I conclude that the raw data represents **WALKING**. The x-axis acceleration values are similar to those in the provided walking data, and the y-axis acceleration values are also similar. The z-axis acceleration values are relatively small, indicating minimal movement in the vertical direction, which is consistent with walking.\n",
      "\n",
      "Please note that this analysis is based on a limited dataset and may not be accurate for all cases. A more comprehensive analysis with a larger dataset would be necessary to confirm the results.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Acceleration in x direction: {accx_test_5[5]}\n",
    "Acceleration in y direction: {accy_test_5[5]}\n",
    "Acceleration in z direction: {accz_test_5[5]}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095bdef1-203a-488a-9427-ec4c2ef5a705",
   "metadata": {},
   "source": [
    "# Q5\n",
    "## Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f599be2-87a9-452f-b3e6-46dedffd25ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 500)\n"
     ]
    }
   ],
   "source": [
    "previous_input = accx_train_5\n",
    "dim = previous_input.shape\n",
    "randomx = np.random.rand(dim[0],500)\n",
    "randomy = np.random.rand(dim[0],500)\n",
    "randomz = np.random.rand(dim[0],500)\n",
    "print(randomx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831381dd-5d72-4ee5-a00f-7a7e0370add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided acceleration data in x, y, and z directions, we can observe the following patterns and characteristics:\n",
      "\n",
      "1. **Range and Distribution**: The acceleration values in all three directions (x, y, z) range from approximately -1 to 1, with most values concentrated between -0.5 and 0.5. This suggests that the activities being performed do not involve extreme accelerations.\n",
      "\n",
      "2. **Patterns in X Direction**: The acceleration in the x direction appears to have a mix of high and low values, with some periods of relatively consistent values (e.g., around indices 100-150). This could indicate activities that involve walking or moving in a straight line.\n",
      "\n",
      "3. **Patterns in Y Direction**: The acceleration in the y direction shows more variability, with frequent changes in magnitude and direction. This could be indicative of activities that involve movement in multiple directions or changes in elevation (e.g., walking upstairs or downstairs).\n",
      "\n",
      "4. **Patterns in Z Direction**: The acceleration in the z direction exhibits a mix of high and low values, with some periods of relatively consistent values (e.g., around indices 200-250). This could indicate activities that involve movement in a vertical direction (e.g., walking upstairs or downstairs).\n",
      "\n",
      "Based on these observations, it is likely that the data represents activities that involve walking, moving in different directions, and changes in elevation. Specifically, the data may represent the following activities:\n",
      "\n",
      "* **Walking**: The mix of high and low values in the x direction, combined with the variability in the y direction, suggests that walking is a likely activity.\n",
      "* **Walking Upstairs**: The frequent changes in magnitude and direction in the y direction, combined with the consistent values in the z direction, suggest that walking upstairs is a likely activity.\n",
      "* **Walking Downstairs**: The similar patterns in the y and z directions, combined with the variability in the x direction, suggest that walking downstairs is also a likely activity.\n",
      "* **Sitting or Standing**: The relatively consistent values in all three directions, particularly in the x direction, suggest that sitting or standing may be a likely activity.\n",
      "\n",
      "However, without more information about the specific activities being performed or the context in which the data was collected, it is difficult to determine the exact activities being represented by the data.\n",
      "\n",
      "To further analyze the data and determine the specific activities being represented, additional techniques such as:\n",
      "\n",
      "* **Time-frequency analysis**: to examine the frequency content of the acceleration signals and identify patterns that may be indicative of specific activities.\n",
      "* **Machine learning**: to train a model to classify the acceleration data into different activity categories.\n",
      "* **Feature extraction**: to extract relevant features from the acceleration data that can be used to distinguish between different activities.\n",
      "\n",
      "may be employed.\n"
     ]
    }
   ],
   "source": [
    "# zero shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities \n",
    "1.Walking\n",
    "2.Walking Upstairs\n",
    "3.Walking Downstairs\n",
    "4.Sitting\n",
    "5.Standing\n",
    "6.Laying\n",
    "\n",
    "your task is to analyse the raw data and say what is the data representing out of the above mentioned activities\n",
    "\n",
    "Acceleration in x direction: {randomx[0]}\n",
    "Acceleration in y direction: {randomy[0]}\n",
    "Acceleration in z direction: {randomz[0]}\n",
    "\"\"\" \n",
    "\n",
    " \n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1d4ef-6c19-45b4-9372-86b1c5f62677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided data, I will attempt to identify the activity represented by the raw data.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "1. The acceleration values in all three directions (x, y, z) are within the range of -1 to 1, which is consistent with the data provided for the six activities.\n",
      "2. The x-axis acceleration values are mostly positive, with some negative values, indicating movement in both forward and backward directions.\n",
      "3. The y-axis acceleration values are mostly positive, with some negative values, indicating movement in both upward and downward directions.\n",
      "4. The z-axis acceleration values are mostly positive, indicating movement in the upward direction.\n",
      "\n",
      "**Comparison with the provided data:**\n",
      "\n",
      "1. **Walking**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking data. However, the y-axis acceleration values are more positive than the walking data, indicating more upward movement.\n",
      "2. **Walking Upstairs**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking upstairs data. The y-axis acceleration values are more positive than the walking data, indicating more upward movement, which is consistent with walking upstairs.\n",
      "3. **Walking Downstairs**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking downstairs data. However, the y-axis acceleration values are more negative than the walking data, indicating more downward movement, which is not consistent with the provided data.\n",
      "4. **Sitting**: The x-axis acceleration values are mostly positive, with some negative values, which is not consistent with the sitting data. The y-axis acceleration values are mostly positive, which is not consistent with the sitting data.\n",
      "5. **Standing**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the standing data. However, the y-axis acceleration values are more positive than the standing data, indicating more upward movement, which is not consistent with the provided data.\n",
      "6. **Laying**: The x-axis acceleration values are mostly positive, with some negative values, which is not consistent with the laying data. The y-axis acceleration values are mostly positive, which is not consistent with the laying data.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the analysis, I would conclude that the raw data represents **Walking Upstairs**. The x-axis acceleration values are mostly positive, with some negative values, indicating movement in both forward and backward directions. The y-axis acceleration values are more positive than the walking data, indicating more upward movement, which is consistent with walking upstairs. The z-axis acceleration values are mostly positive, indicating movement in the upward direction, which is also consistent with walking upstairs.\n",
      "\n",
      "Please note that this analysis is based on a visual inspection of the data and may not be entirely accurate. A more rigorous analysis using machine learning algorithms or statistical methods may be necessary to confirm the results.\n"
     ]
    }
   ],
   "source": [
    "#few shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "Acceleration in x direction: {accx_train_3.ravel()}\n",
    "Acceleration in y direction: {accy_train_3.ravel()}\n",
    "Acceleration in z direction: {accz_train_3.ravel()}\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "Acceleration in x direction: {accx_train_5.ravel()}\n",
    "Acceleration in y direction: {accy_train_5.ravel()}\n",
    "Acceleration in z direction: {accz_train_5.ravel()}\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Acceleration in x direction: {randomx[4]}\n",
    "Acceleration in y direction: {randomy[4]}\n",
    "Acceleration in z direction: {randomz[4]}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f67ded-cf57-40bf-b4e2-b32d3b5d66f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
