{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4990aa01-2e28-4f6b-be28-b65e1b3297dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret import key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ea4ba6-0336-43bd-9f11-e26f98177fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "from MakeDataset import X_train,X_test,y_train,y_test\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import os\n",
    "\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING'            ,\n",
    "    2: 'WALKING_UPSTAIRS'   ,\n",
    "    3: 'WALKING_DOWNSTAIRS' ,\n",
    "    4: 'SITTING'            ,\n",
    "    5: 'STANDING'           ,\n",
    "    6: 'LAYING'             ,\n",
    "}\n",
    "\n",
    "columns = [\"accx\",\"accy\",\"accz\"]\n",
    "subject_test = [10,12,13,18,2,20,24,4,9]\n",
    "subject_train = [1,11,14,15,16,17,19,21,22,23,25,26,27,28,29,3,30,5,6,7,8]\n",
    "\n",
    "Groq_Token = key\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model = 'llama3.1-70b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f4838a-9ea9-4498-8d96-b36a000a1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "accx_train = X_train[:,:,0]\n",
    "accy_train = X_train[:,:,1]\n",
    "accz_train = X_train[:,:,2]\n",
    "\n",
    "accx_train_1 = accx_train[np.where(y_train==1)]\n",
    "accy_train_1 = accy_train[np.where(y_train==1)]\n",
    "accz_train_1 = accz_train[np.where(y_train==1)]\n",
    "\n",
    "accx_train_2 = accx_train[np.where(y_train==2)]\n",
    "accy_train_2 = accy_train[np.where(y_train==2)]\n",
    "accz_train_2 = accz_train[np.where(y_train==2)]\n",
    "\n",
    "accx_train_3 = accx_train[np.where(y_train==3)]\n",
    "accy_train_3 = accy_train[np.where(y_train==3)]\n",
    "accz_train_3 = accz_train[np.where(y_train==3)]\n",
    "\n",
    "accx_train_4 = accx_train[np.where(y_train==4)]\n",
    "accy_train_4 = accy_train[np.where(y_train==4)]\n",
    "accz_train_4 = accz_train[np.where(y_train==4)]\n",
    "\n",
    "accx_train_5 = accx_train[np.where(y_train==5)]\n",
    "accy_train_5 = accy_train[np.where(y_train==5)]\n",
    "accz_train_5 = accz_train[np.where(y_train==5)]\n",
    "\n",
    "accx_train_6 = accx_train[np.where(y_train==6)]\n",
    "accy_train_6 = accy_train[np.where(y_train==6)]\n",
    "accz_train_6 = accz_train[np.where(y_train==6)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accx_test = X_test[:,:,0]\n",
    "accy_test = X_test[:,:,1]\n",
    "accz_test = X_test[:,:,2]\n",
    "\n",
    "accx_test_1 = accx_test[np.where(y_test==1)]\n",
    "accy_test_1 = accy_test[np.where(y_test==1)]\n",
    "accz_test_1 = accz_test[np.where(y_test==1)]\n",
    "\n",
    "accx_test_2 = accx_test[np.where(y_test==2)]\n",
    "accy_test_2 = accy_test[np.where(y_test==2)]\n",
    "accz_test_2 = accz_test[np.where(y_test==2)]\n",
    "\n",
    "accx_test_3 = accx_test[np.where(y_test==3)]\n",
    "accy_test_3 = accy_test[np.where(y_test==3)]\n",
    "accz_test_3 = accz_test[np.where(y_test==3)]\n",
    "\n",
    "accx_test_4 = accx_test[np.where(y_test==4)]\n",
    "accy_test_4 = accy_test[np.where(y_test==4)]\n",
    "accz_test_4 = accz_test[np.where(y_test==4)]\n",
    "\n",
    "accx_test_5 = accx_test[np.where(y_test==5)]\n",
    "accy_test_5 = accy_test[np.where(y_test==5)]\n",
    "accz_test_5 = accz_test[np.where(y_test==5)]\n",
    "\n",
    "accx_test_6 = accx_test[np.where(y_test==6)]\n",
    "accy_test_6 = accy_test[np.where(y_test==6)]\n",
    "accz_test_6 = accz_test[np.where(y_test==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea07eaa-ffaa-4827-b367-610e29c1c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accx_train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66ecd1-5ac0-4585-b0cd-466d92ddcffa",
   "metadata": {},
   "source": [
    "# Q1 \n",
    "## Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98992901-f7cb-4234-bc23-6afe2336fb47",
   "metadata": {},
   "source": [
    "Comparing zero shot with few shot.\n",
    "Zero shot learning aims to recognize the instances from classes that it has never seen before. Generalizing from seen classes to unseen ones purely based on semantic information, which can be quite difficult if the semantic relationships are weak or ambiguous.\n",
    "\n",
    "Whereas in few shot learning the model has access to a small number of samples from the target class, making it easier to fine-tune or adjust its internal representations for better accuracy.\n",
    "\n",
    "Out of the following two cells the first one is implemtation of zero shot and the other is of few shot. We can observe that in the first response when the data is directly given for classification the model generalizes the idea of movement in x,y and z directions and using it as premises it classifies the activities. It tries to use the general idea e.g while walking the acceleration in x should be considerably high with respect to the other axis. Similar inferences are made for all the activities.\n",
    "\n",
    "While in the few shot learning, the model first analyses the data provided for each of the activities and performs some statistical operations and builds the conclusion. Here, the accuracy rate is significantly high as compared to former case. This is beacuse the model now has the acces to relevant data to study the examples and provide better inferences.\n",
    "\n",
    "So, to put answer in simple words, the zero shot approach doesn't have access to the data and it generalizes its own understandings to the given dataset.On contrary in the few shot approach the model has access to some samples of the data to learn from and then accordingly classify the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1d8519-34fb-41e7-ad64-5cfe41f63811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided acceleration data in x, y, and z directions, we can observe the following patterns:\n",
      "\n",
      "1. **Walking**: The acceleration in the x-direction is relatively consistent, with a range of approximately 0.5 to 1.5 g. The y-direction acceleration is mostly negative, indicating a downward motion, with a range of approximately -0.5 to -2.5 g. The z-direction acceleration is mostly positive, indicating an upward motion, with a range of approximately 0.5 to 2.5 g.\n",
      "\n",
      "2. **Walking Upstairs**: The acceleration in the x-direction is similar to walking, but with a slightly higher range (approximately 0.5 to 2.0 g). The y-direction acceleration is more negative, indicating a steeper downward motion, with a range of approximately -1.0 to -4.0 g. The z-direction acceleration is more positive, indicating a more pronounced upward motion, with a range of approximately 1.0 to 4.0 g.\n",
      "\n",
      "3. **Walking Downstairs**: The acceleration in the x-direction is similar to walking, but with a slightly lower range (approximately 0.2 to 1.2 g). The y-direction acceleration is less negative, indicating a less steep downward motion, with a range of approximately -0.5 to -2.0 g. The z-direction acceleration is less positive, indicating a less pronounced upward motion, with a range of approximately 0.2 to 1.5 g.\n",
      "\n",
      "4. **Sitting**: The acceleration in all directions is relatively low, with ranges of approximately 0.1 to 0.5 g in the x-direction, -0.1 to -0.5 g in the y-direction, and 0.1 to 0.5 g in the z-direction.\n",
      "\n",
      "5. **Standing**: The acceleration in all directions is relatively low, with ranges of approximately 0.1 to 0.5 g in the x-direction, -0.1 to -0.5 g in the y-direction, and 0.1 to 0.5 g in the z-direction.\n",
      "\n",
      "6. **Laying**: The acceleration in all directions is relatively low, with ranges of approximately 0.1 to 0.5 g in the x-direction, -0.1 to -0.5 g in the y-direction, and 0.1 to 0.5 g in the z-direction.\n",
      "\n",
      "Based on these patterns, we can make an educated guess about the activity being performed. However, without more information or context, it's challenging to determine the exact activity with certainty.\n",
      "\n",
      "That being said, if I had to make an educated guess based on the provided data, I would say that the activity being performed is likely **Walking**. The acceleration patterns in the x, y, and z directions seem to match the expected patterns for walking, with a relatively consistent x-direction acceleration, a negative y-direction acceleration indicating a downward motion, and a positive z-direction acceleration indicating an upward motion.\n",
      "\n",
      "Please note that this is just an educated guess, and more information or context would be needed to determine the exact activity with certainty.\n"
     ]
    }
   ],
   "source": [
    "# zero shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities \n",
    "1.Walking\n",
    "2.Walking Upstairs\n",
    "3.Walking Downstairs\n",
    "4.Sitting\n",
    "5.Standing\n",
    "6.Laying\n",
    "\n",
    "your task is to analyse the raw data and say what is the data representing out of the above mentioned activities\n",
    "\n",
    "Acceleration in x direction: {accx_test_1[0]}\n",
    "Acceleration in y direction: {accy_test_1[0]}\n",
    "Acceleration in z direction: {accz_test_1[0]}\n",
    "\"\"\" \n",
    "\n",
    " \n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cee8b14-79eb-4cc9-9028-cf3766e21cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, I will analyze the acceleration patterns in the x, y, and z directions to determine the activity being performed.\n",
      "\n",
      "**Acceleration in x direction:**\n",
      "\n",
      "The acceleration in the x direction is relatively stable, with values ranging from 0.95 to 1.01. This suggests that the activity is not involving significant movement in the x direction.\n",
      "\n",
      "**Acceleration in y direction:**\n",
      "\n",
      "The acceleration in the y direction is mostly negative, with values ranging from -0.16 to -0.05. This suggests that the activity is involving some movement in the y direction, possibly with a slight downward trend.\n",
      "\n",
      "**Acceleration in z direction:**\n",
      "\n",
      "The acceleration in the z direction is mostly positive, with values ranging from 0.28 to 0.31. This suggests that the activity is involving some movement in the z direction, possibly with a slight upward trend.\n",
      "\n",
      "**Comparison with the provided data:**\n",
      "\n",
      "Comparing the acceleration patterns with the provided data, I notice that the patterns are similar to those of the \"STANDING\" activity. The acceleration in the x direction is relatively stable, while the acceleration in the y direction is mostly negative, and the acceleration in the z direction is mostly positive.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the analysis, I conclude that the provided data represents the \"STANDING\" activity.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "Acceleration in x direction: {accx_train_3.ravel()}\n",
    "Acceleration in y direction: {accy_train_3.ravel()}\n",
    "Acceleration in z direction: {accz_train_3.ravel()}\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "Acceleration in x direction: {accx_train_5.ravel()}\n",
    "Acceleration in y direction: {accy_train_5.ravel()}\n",
    "Acceleration in z direction: {accz_train_5.ravel()}\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Acceleration in x direction: {accx_test_5[4]}\n",
    "Acceleration in y direction: {accy_test_5[4]}\n",
    "Acceleration in z direction: {accz_test_5[4]}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52e5d9-a615-47b5-ba89-92e51579c066",
   "metadata": {},
   "source": [
    "# Q2\n",
    "## Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91638825-01ef-406b-a37e-f497ff86f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "1\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "2\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "4\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "6\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "7\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "8\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "9\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "10\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "11\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "12\n",
      "Actual LAYING\n",
      "Predicted SITTING\n",
      "\n",
      "13\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "14\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "15\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "16\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "17\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "18\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "20\n",
      "Actual SITTING\n",
      "Predicted STANDING\n",
      "\n",
      "21\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "22\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "23\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "24\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "28\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "29\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "30\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "31\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "32\n",
      "Actual SITTING\n",
      "Predicted SITTING\n",
      "\n",
      "33\n",
      "Actual SITTING\n",
      "Predicted SITTING\n",
      "\n",
      "34\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "35\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "37\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "38\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "40\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "41\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "42\n",
      "Actual WALKING\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "43\n",
      "Actual SITTING\n",
      "Predicted SITTING\n",
      "\n",
      "44\n",
      "Actual SITTING\n",
      "Predicted STANDING\n",
      "\n",
      "46\n",
      "Actual STANDING\n",
      "Predicted STANDING\n",
      "\n",
      "48\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "49\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "50\n",
      "Actual WALKING_DOWNSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "51\n",
      "Actual LAYING\n",
      "Predicted LAYING\n",
      "\n",
      "52\n",
      "Actual WALKING_UPSTAIRS\n",
      "Predicted WALKING_UPSTAIRS\n",
      "\n",
      "53\n",
      "Actual SITTING\n",
      "Predicted STANDING\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "idxs = []\n",
    "\n",
    "for i in range(accx_test.shape[0]):\n",
    "    feed_x = accx_test[i]\n",
    "    feed_y = accy_test[i]\n",
    "    feed_z = accz_test[i]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "    This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "    there are multiple data readingsof same activity within the single one provided to you\n",
    "    1.WALKING\n",
    "    Acceleration in x direction: {accx_train_1.ravel()}\n",
    "    Acceleration in y direction: {accy_train_1.ravel()}\n",
    "    Acceleration in z direction: {accz_train_1.ravel()}\n",
    "    \n",
    "    2.WALKING_UPSTAIRS\n",
    "    Acceleration in x direction: {accx_train_2.ravel()}\n",
    "    Acceleration in y direction: {accy_train_2.ravel()}\n",
    "    Acceleration in z direction: {accz_train_2.ravel()}\n",
    "    \n",
    "    3.WALKING_DOWNSTAIRS\n",
    "    Acceleration in x direction: {accx_train_3.ravel()}\n",
    "    Acceleration in y direction: {accy_train_3.ravel()}\n",
    "    Acceleration in z direction: {accz_train_3.ravel()}\n",
    "    \n",
    "    4.SITTING\n",
    "    Acceleration in x direction: {accx_train_4.ravel()}\n",
    "    Acceleration in y direction: {accy_train_4.ravel()}\n",
    "    Acceleration in z direction: {accz_train_4.ravel()}\n",
    "    \n",
    "    5.STANDING\n",
    "    Acceleration in x direction: {accx_train_5.ravel()}\n",
    "    Acceleration in y direction: {accy_train_5.ravel()}\n",
    "    Acceleration in z direction: {accz_train_5.ravel()}\n",
    "    \n",
    "    6.LAYING\n",
    "    Acceleration in x direction: {accx_train_6.ravel()}\n",
    "    Acceleration in y direction: {accy_train_6.ravel()}\n",
    "    Acceleration in z direction: {accz_train_6.ravel()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "    Acceleration in x direction: {feed_x}\n",
    "    Acceleration in y direction: {feed_y}\n",
    "    Acceleration in z direction: {feed_z}\n",
    "\n",
    "    I am collecting data for calculating the accuracy of llm so the output needs to be clean\n",
    "    Give the answers in form of keys and no extra explanation is required\n",
    "    1:WALKING\n",
    "    2:WALKING_DOWNSTAIRS\n",
    "    3:WALKING_UPSTAIRS\n",
    "    4:SITTING\n",
    "    5:STANDING\n",
    "    6:LAYING\n",
    "    \"\"\" \n",
    "    \n",
    "    model_name = model\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    # print(answer.content)\n",
    "    \n",
    "    for key,values in ACTIVITIES.items():\n",
    "        words = answer.content.split()\n",
    "        required = words[-1].split(\":\")[-1]\n",
    "        if values == required:\n",
    "            predictions.append(key)\n",
    "            idxs.append(i)\n",
    "            print(i)\n",
    "            print(\"Actual\",ACTIVITIES[y_test[i]])\n",
    "            print(\"Predicted\",values)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c47f42a-570c-4e0a-a12e-9e08a3b4984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 5, 2, 5, 2, 2, 6, 5, 4, 5, 6, 2, 6, 5, 2, 5, 2, 2, 2, 2, 2, 2, 6, 2, 4, 4, 2, 6, 2, 2, 2, 2, 2, 4, 5, 5, 2, 2, 2, 6, 2, 5]\n",
      "[3 1 2 5 1 5 3 2 6 5 6 5 6 1 6 5 2 4 3 2 2 1 1 2 6 2 4 4 3 6 3 1 3 2 1 4 4\n",
      " 5 3 3 3 6 2 4]\n",
      "Accuracy of few shot: 54.55%\n"
     ]
    }
   ],
   "source": [
    "# Checking the predictions data\n",
    "print(predictions)\n",
    "print(y_test[idxs])\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(p == y for p, y in zip(predictions, y_test[idxs]))\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of few shot: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835d923-d308-4208-b03f-b7df4b50ead6",
   "metadata": {},
   "source": [
    "# Q3\n",
    "## What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f2096-171c-4325-b72d-928ff780981b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa48b14a-46d7-4d0b-83c3-6e2f5cc27d7e",
   "metadata": {},
   "source": [
    "# Q4\n",
    "## What does the model classify when given input from an entirely new activity that it hasn't seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8465358-5855-4d33-b1a8-c36a52a7e392",
   "metadata": {},
   "source": [
    "In this scenario, the model has been trained on data from only four specific activities, excluding the 'Standing' and 'Walking' activities, although these two activities are included in the list of possible predictions. When the model is given data related to 'Standing' or 'Walking,' it tends to force the data into one of the four activities it has seen during training, often failing to recognize or accurately classify the 'Standing' or 'Walking' activities. As a result, the model consistently misclassifies these activities because it lacks the necessary training data to correctly identify them, despite their presence in the prediction list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf04aba2-b217-40fd-9d02-eb711b5dcb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided data, I will attempt to identify the activity represented by the raw data.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "1. The acceleration values in the x, y, and z directions are relatively stable, with some fluctuations.\n",
      "2. The x-axis acceleration values are mostly positive, indicating movement in the forward direction.\n",
      "3. The y-axis acceleration values are mostly negative, indicating movement in the downward direction.\n",
      "4. The z-axis acceleration values are relatively small, indicating minimal movement in the vertical direction.\n",
      "\n",
      "**Comparison with the provided activities:**\n",
      "\n",
      "1. **WALKING**: The x-axis acceleration values are similar to those in the provided walking data, with a range of approximately 0.8 to 1.2. The y-axis acceleration values are also similar, with a range of approximately -0.2 to -0.1.\n",
      "2. **WALKING_UPSTAIRS**: The x-axis acceleration values are higher than those in the provided walking data, with a range of approximately 1.2 to 1.5. The y-axis acceleration values are also higher, with a range of approximately -0.1 to 0.1.\n",
      "3. **WALKING_DOWNSTAIRS**: Not enough data is provided to make a comparison.\n",
      "4. **SITTING**: The x-axis acceleration values are lower than those in the provided walking data, with a range of approximately 0.7 to 0.9. The y-axis acceleration values are also lower, with a range of approximately 0.4 to 0.5.\n",
      "5. **STANDING**: Not enough data is provided to make a comparison.\n",
      "6. **LAYING**: The x-axis acceleration values are lower than those in the provided walking data, with a range of approximately 0.2 to 0.4. The y-axis acceleration values are also lower, with a range of approximately 0.5 to 0.6.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the observations and comparisons, I conclude that the raw data represents **WALKING**. The x-axis acceleration values are similar to those in the provided walking data, and the y-axis acceleration values are also similar. The z-axis acceleration values are relatively small, indicating minimal movement in the vertical direction, which is consistent with walking.\n",
      "\n",
      "Please note that this analysis is based on a limited dataset and may not be accurate for all cases. A more comprehensive analysis with a larger dataset would be necessary to confirm the results.\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Acceleration in x direction: {accx_test_5[5]}\n",
    "Acceleration in y direction: {accy_test_5[5]}\n",
    "Acceleration in z direction: {accz_test_5[5]}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095bdef1-203a-488a-9427-ec4c2ef5a705",
   "metadata": {},
   "source": [
    "# Q5\n",
    "## Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f599be2-87a9-452f-b3e6-46dedffd25ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 500)\n"
     ]
    }
   ],
   "source": [
    "previous_input = accx_train_5\n",
    "dim = previous_input.shape\n",
    "randomx = np.random.rand(dim[0],500)\n",
    "randomy = np.random.rand(dim[0],500)\n",
    "randomz = np.random.rand(dim[0],500)\n",
    "print(randomx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831381dd-5d72-4ee5-a00f-7a7e0370add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided acceleration data in x, y, and z directions, we can observe the following patterns and characteristics:\n",
      "\n",
      "1. **Range and Distribution**: The acceleration values in all three directions (x, y, z) range from approximately -1 to 1, with most values concentrated between -0.5 and 0.5. This suggests that the activities being performed do not involve extreme accelerations.\n",
      "\n",
      "2. **Patterns in X Direction**: The acceleration in the x direction appears to have a mix of high and low values, with some periods of relatively consistent values (e.g., around indices 100-150). This could indicate activities that involve walking or moving in a straight line.\n",
      "\n",
      "3. **Patterns in Y Direction**: The acceleration in the y direction shows more variability, with frequent changes in magnitude and direction. This could be indicative of activities that involve movement in multiple directions or changes in elevation (e.g., walking upstairs or downstairs).\n",
      "\n",
      "4. **Patterns in Z Direction**: The acceleration in the z direction exhibits a mix of high and low values, with some periods of relatively consistent values (e.g., around indices 200-250). This could indicate activities that involve movement in a vertical direction (e.g., walking upstairs or downstairs).\n",
      "\n",
      "Based on these observations, it is likely that the data represents activities that involve walking, moving in different directions, and changes in elevation. Specifically, the data may represent the following activities:\n",
      "\n",
      "* **Walking**: The mix of high and low values in the x direction, combined with the variability in the y direction, suggests that walking is a likely activity.\n",
      "* **Walking Upstairs**: The frequent changes in magnitude and direction in the y direction, combined with the consistent values in the z direction, suggest that walking upstairs is a likely activity.\n",
      "* **Walking Downstairs**: The similar patterns in the y and z directions, combined with the variability in the x direction, suggest that walking downstairs is also a likely activity.\n",
      "* **Sitting or Standing**: The relatively consistent values in all three directions, particularly in the x direction, suggest that sitting or standing may be a likely activity.\n",
      "\n",
      "However, without more information about the specific activities being performed or the context in which the data was collected, it is difficult to determine the exact activities being represented by the data.\n",
      "\n",
      "To further analyze the data and determine the specific activities being represented, additional techniques such as:\n",
      "\n",
      "* **Time-frequency analysis**: to examine the frequency content of the acceleration signals and identify patterns that may be indicative of specific activities.\n",
      "* **Machine learning**: to train a model to classify the acceleration data into different activity categories.\n",
      "* **Feature extraction**: to extract relevant features from the acceleration data that can be used to distinguish between different activities.\n",
      "\n",
      "may be employed.\n"
     ]
    }
   ],
   "source": [
    "# zero shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities \n",
    "1.Walking\n",
    "2.Walking Upstairs\n",
    "3.Walking Downstairs\n",
    "4.Sitting\n",
    "5.Standing\n",
    "6.Laying\n",
    "\n",
    "your task is to analyse the raw data and say what is the data representing out of the above mentioned activities\n",
    "\n",
    "Acceleration in x direction: {randomx[0]}\n",
    "Acceleration in y direction: {randomy[0]}\n",
    "Acceleration in z direction: {randomz[0]}\n",
    "\"\"\" \n",
    "\n",
    " \n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b1d4ef-6c19-45b4-9372-86b1c5f62677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the provided data, I will attempt to identify the activity represented by the raw data.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "1. The acceleration values in all three directions (x, y, z) are within the range of -1 to 1, which is consistent with the data provided for the six activities.\n",
      "2. The x-axis acceleration values are mostly positive, with some negative values, indicating movement in both forward and backward directions.\n",
      "3. The y-axis acceleration values are mostly positive, with some negative values, indicating movement in both upward and downward directions.\n",
      "4. The z-axis acceleration values are mostly positive, indicating movement in the upward direction.\n",
      "\n",
      "**Comparison with the provided data:**\n",
      "\n",
      "1. **Walking**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking data. However, the y-axis acceleration values are more positive than the walking data, indicating more upward movement.\n",
      "2. **Walking Upstairs**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking upstairs data. The y-axis acceleration values are more positive than the walking data, indicating more upward movement, which is consistent with walking upstairs.\n",
      "3. **Walking Downstairs**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the walking downstairs data. However, the y-axis acceleration values are more negative than the walking data, indicating more downward movement, which is not consistent with the provided data.\n",
      "4. **Sitting**: The x-axis acceleration values are mostly positive, with some negative values, which is not consistent with the sitting data. The y-axis acceleration values are mostly positive, which is not consistent with the sitting data.\n",
      "5. **Standing**: The x-axis acceleration values are mostly positive, with some negative values, which is consistent with the standing data. However, the y-axis acceleration values are more positive than the standing data, indicating more upward movement, which is not consistent with the provided data.\n",
      "6. **Laying**: The x-axis acceleration values are mostly positive, with some negative values, which is not consistent with the laying data. The y-axis acceleration values are mostly positive, which is not consistent with the laying data.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the analysis, I would conclude that the raw data represents **Walking Upstairs**. The x-axis acceleration values are mostly positive, with some negative values, indicating movement in both forward and backward directions. The y-axis acceleration values are more positive than the walking data, indicating more upward movement, which is consistent with walking upstairs. The z-axis acceleration values are mostly positive, indicating movement in the upward direction, which is also consistent with walking upstairs.\n",
      "\n",
      "Please note that this analysis is based on a visual inspection of the data and may not be entirely accurate. A more rigorous analysis using machine learning algorithms or statistical methods may be necessary to confirm the results.\n"
     ]
    }
   ],
   "source": [
    "#few shot\n",
    "\n",
    "query = f\"\"\"\n",
    "You are being provided with the experimental data containing the acceleration in x,y and z directions. \n",
    "This data is collected by humans performing  following activities and the data is 2 dimensional that means that \n",
    "there are multiple data readingsof same activity within the single one provided to you\n",
    "1.WALKING\n",
    "Acceleration in x direction: {accx_train_1.ravel()}\n",
    "Acceleration in y direction: {accy_train_1.ravel()}\n",
    "Acceleration in z direction: {accz_train_1.ravel()}\n",
    "\n",
    "2.WALKING_UPSTAIRS\n",
    "Acceleration in x direction: {accx_train_2.ravel()}\n",
    "Acceleration in y direction: {accy_train_2.ravel()}\n",
    "Acceleration in z direction: {accz_train_2.ravel()}\n",
    "\n",
    "3.WALKING_DOWNSTAIRS\n",
    "Acceleration in x direction: {accx_train_3.ravel()}\n",
    "Acceleration in y direction: {accy_train_3.ravel()}\n",
    "Acceleration in z direction: {accz_train_3.ravel()}\n",
    "\n",
    "4.SITTING\n",
    "Acceleration in x direction: {accx_train_4.ravel()}\n",
    "Acceleration in y direction: {accy_train_4.ravel()}\n",
    "Acceleration in z direction: {accz_train_4.ravel()}\n",
    "\n",
    "5.STANDING\n",
    "Acceleration in x direction: {accx_train_5.ravel()}\n",
    "Acceleration in y direction: {accy_train_5.ravel()}\n",
    "Acceleration in z direction: {accz_train_5.ravel()}\n",
    "\n",
    "6.LAYING\n",
    "Acceleration in x direction: {accx_train_6.ravel()}\n",
    "Acceleration in y direction: {accy_train_6.ravel()}\n",
    "Acceleration in z direction: {accz_train_6.ravel()}\n",
    "\n",
    "\n",
    "\n",
    "your task is to analyse the data given above and then analyse the following raw data and say what is the data representing out of the above mentioned activities\n",
    "Acceleration in x direction: {randomx[4]}\n",
    "Acceleration in y direction: {randomy[4]}\n",
    "Acceleration in z direction: {randomz[4]}\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "model_name = model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f67ded-cf57-40bf-b4e2-b32d3b5d66f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
